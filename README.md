# Comparing-Mamba-and-Transformer-on-Text-Classification
This is my college project demonstration.  
We mainly focus on how the Mamba architecture work.  
We compare Mamba and Transformer by two different text classification dataset.  
And the cmoparisons include the accuracy and the resouce (GPU usage , training time , inference time ...)  
## Comparison Result  
|           | Mb-IMDb-1 |   TF-IMDb-1   |  Gain of Mamba  |
| --------- | --------- | ------------- | --------------- |
| 模型參數量 |  354,018  |393,121  |9.9%|
|Best accuracy |   86.3%   | 87.8%  |-1.5%|
| GPU 記憶體最高使用量(MB) |   244  | 558 |52.3%|
